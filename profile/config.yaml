default-resources:
  - disk=4
  - mem=16
  - hrs=12
cluster:
  mkdir -p logs/{rule} &&
  sbatch
    --account=hsiehph
    --partition=agsmall,aglarge
    --nodes=1
    --ntasks-per-node=1
    --cpus-per-task={threads}
    --mem={resources.mem}g
    --tmp={resources.disk}g
    --time={resources.hrs}:00:00
    --job-name=smk-{rule}-{wildcards}
    --output=logs/{rule}/{rule}_{wildcards}.%j.out
    --export=all
    --parsable # Required to pass job IDs to scancel
jobs: 200 
rerun-incomplete: True
# I think these are implied by --slurm
#cluster-cancel: scancel
#cluster-cancel-nargs: 500 # cancel 500 jobs at a time, all will still be canceled
printshellcmds: True
reason: True
show-failed-logs: True 
latency-wait: 60
cluster-status: status-sacct.sh
use-conda: True
max-jobs-per-second: 200 
#rerun-triggers: mtime 
#restart-times: 5
